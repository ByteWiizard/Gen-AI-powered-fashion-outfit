{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Kj8mGkmH0xgA",
        "outputId": "6a793110-884d-4f59-89ec-9c5eced9b98a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'ganspace' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n ganspace ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies (restart runtime after installing)\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "# !pip install ninja gradio fbpca boto3 requests==2.23.0 urllib3==1.25.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwf-gggHtA_t",
        "outputId": "68f7afee-6889-4f9c-97d0-de9ba931c206"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/mfrashad/ClothingGAN.git\n",
        "# %cd ClothingGAN/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "2BYsIETVtGnF",
        "outputId": "e3b5c2ac-9c18-4917-de0f-1f2c126aa696"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Install other dependencies\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "!git submodule update --init --recursive\n",
        "# !python -c \"import nltk; nltk.download('wordnet')\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/nltk/downloader.py\", line 777, in download\n",
            "    for msg in self.incr_download(info_or_id, download_dir, force):\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/nltk/downloader.py\", line 629, in incr_download\n",
            "    info = self._info_or_id(info_or_id)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/nltk/downloader.py\", line 603, in _info_or_id\n",
            "    return self.info(info_or_id)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/nltk/downloader.py\", line 1009, in info\n",
            "    self._update_index()\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/nltk/downloader.py\", line 952, in _update_index\n",
            "    ElementTree.parse(urlopen(self._url)).getroot()\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import nltk; nltk.download('wordnet')\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 1.13.1+cu117\n",
            "Is CUDA enabled? True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"Torch version:\",torch.__version__)\n",
        "\n",
        "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJg91yvSwKi3",
        "outputId": "15c2285c-e8da-45b9-bdc2-9bab3709b270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StyleGAN2: Optimized CUDA op FusedLeakyReLU not available, using native PyTorch fallback.\n",
            "StyleGAN2: Optimized CUDA op UpFirDn2d not available, using native PyTorch fallback.\n"
          ]
        }
      ],
      "source": [
        "#@title Load Model\n",
        "selected_model = 'lookbook'\n",
        "\n",
        "# Load model\n",
        "from IPython.utils import io\n",
        "import torch\n",
        "import PIL\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from models import get_instrumented_model\n",
        "from decomposition import get_or_compute\n",
        "from config import Config\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "# Speed up computation\n",
        "torch.autograd.set_grad_enabled(False)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Specify model to use\n",
        "config = Config(\n",
        "  model='StyleGAN2',\n",
        "  layer='style',\n",
        "  output_class=selected_model,\n",
        "  components=80,\n",
        "  use_w=True,\n",
        "  batch_size=5_000, # style layer quite small\n",
        ")\n",
        "\n",
        "inst = get_instrumented_model(config.model, config.output_class,\n",
        "                              config.layer, torch.device('cuda'), use_w=config.use_w)\n",
        "\n",
        "path_to_components = get_or_compute(config, inst)\n",
        "\n",
        "model = inst.model\n",
        "\n",
        "comps = np.load(path_to_components)\n",
        "lst = comps.files\n",
        "latent_dirs = []\n",
        "latent_stdevs = []\n",
        "\n",
        "load_activations = False\n",
        "\n",
        "for item in lst:\n",
        "    if load_activations:\n",
        "      if item == 'act_comp':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_dirs.append(comps[item][i])\n",
        "      if item == 'act_stdev':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_stdevs.append(comps[item][i])\n",
        "    else:\n",
        "      if item == 'lat_comp':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_dirs.append(comps[item][i])\n",
        "      if item == 'lat_stdev':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_stdevs.append(comps[item][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "uCR_3Ghos2kK"
      },
      "outputs": [],
      "source": [
        "#@title Define functions\n",
        "from ipywidgets import fixed\n",
        "\n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "def name_direction(sender):\n",
        "  if not text.value:\n",
        "    print('Please name the direction before saving')\n",
        "    return\n",
        "    \n",
        "  if num in named_directions.values():\n",
        "    target_key = list(named_directions.keys())[list(named_directions.values()).index(num)]\n",
        "    print(f'Direction already named: {target_key}')\n",
        "    print(f'Overwriting... ')\n",
        "    del(named_directions[target_key])\n",
        "  named_directions[text.value] = [num, start_layer.value, end_layer.value]\n",
        "  save_direction(random_dir, text.value)\n",
        "  for item in named_directions:\n",
        "    print(item, named_directions[item])\n",
        "\n",
        "def save_direction(direction, filename):\n",
        "  filename += \".npy\"\n",
        "  np.save(filename, direction, allow_pickle=True, fix_imports=True)\n",
        "  print(f'Latent direction saved as {filename}')\n",
        "\n",
        "def mix_w(w1, w2, content, style):\n",
        "    for i in range(0,5):\n",
        "        w2[i] = w1[i] * (1 - content) + w2[i] * content\n",
        "\n",
        "    for i in range(5, 16):\n",
        "        w2[i] = w1[i] * (1 - style) + w2[i] * style\n",
        "    \n",
        "    return w2\n",
        "\n",
        "def display_sample_pytorch(seed, truncation, directions, distances, scale, start, end, w=None, disp=True, save=None, noise_spec=None):\n",
        "    # blockPrint()\n",
        "    model.truncation = truncation\n",
        "    if w is None:\n",
        "        w = model.sample_latent(1, seed=seed).detach().cpu().numpy()\n",
        "        w = [w]*model.get_max_latents() # one per layer\n",
        "    else:\n",
        "        w = [np.expand_dims(x, 0) for x in w]\n",
        "    \n",
        "    for l in range(start, end):\n",
        "      for i in range(len(directions)):\n",
        "        w[l] = w[l] + directions[i] * distances[i] * scale\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8)).resize((500,500),Image.LANCZOS)\n",
        "    \n",
        "    \n",
        "    if save is not None:\n",
        "      if disp == False:\n",
        "        print(save)\n",
        "      final_im.save(f'out/{seed}_{save:05}.png')\n",
        "    if disp:\n",
        "      display(final_im)\n",
        "    \n",
        "    return final_im\n",
        "\n",
        "def generate_mov(seed, truncation, direction_vec, scale, layers, n_frames, out_name = 'out', noise_spec = None, loop=True):\n",
        "  \"\"\"Generates a mov moving back and forth along the chosen direction vector\"\"\"\n",
        "  # Example of reading a generated set of images, and storing as MP4.\n",
        "  %mkdir out\n",
        "  movieName = f'out/{out_name}.mp4'\n",
        "  offset = -10\n",
        "  step = 20 / n_frames\n",
        "  imgs = []\n",
        "  for i in log_progress(range(n_frames), name = \"Generating frames\"):\n",
        "    print(f'\\r{i} / {n_frames}', end='')\n",
        "    w = model.sample_latent(1, seed=seed).cpu().numpy()\n",
        "\n",
        "    model.truncation = truncation\n",
        "    w = [w]*model.get_max_latents() # one per layer\n",
        "    for l in layers:\n",
        "      if l <= model.get_max_latents():\n",
        "          w[l] = w[l] + direction_vec * offset * scale\n",
        "\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8))\n",
        "    imgs.append(out)\n",
        "    #increase offset\n",
        "    offset += step\n",
        "  if loop:\n",
        "    imgs += imgs[::-1]\n",
        "  with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
        "        writer.append_data(img_as_ubyte(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "jneXxZnNwHo5",
        "outputId": "c8e2b76e-3a00-47f5-ba2d-51606f09ee93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/inputs.py:90: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/inputs.py:99: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  optional=optional,\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/inputs.py:60: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/inputs.py:62: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(value=default, label=label, optional=optional)\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_1\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_2\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_3\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_4\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_5\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_6\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_7\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_8\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_9\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_10\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_11\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_12\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
            "/home/adarsh/anaconda3/envs/ganspace/lib/python3.7/site-packages/gradio/blocks.py:263: UserWarning: api_name predict already exists, using predict_13\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Demo UI\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def generate_image(seed1, seed2, content, style, truncation, c0, c1, c2, c3, c4, c5, c6, start_layer, end_layer):\n",
        "    seed1 = int(seed1)\n",
        "    seed2 = int(seed2)\n",
        "\n",
        "    scale = 1\n",
        "    params = {'c0': c0,\n",
        "          'c1': c1,\n",
        "          'c2': c2,\n",
        "          'c3': c3,\n",
        "          'c4': c4,\n",
        "          'c5': c5,\n",
        "          'c6': c6}\n",
        "\n",
        "    param_indexes = {'c0': 0,\n",
        "              'c1': 1,\n",
        "              'c2': 2,\n",
        "              'c3': 3,\n",
        "              'c4': 4,\n",
        "              'c5': 5,\n",
        "              'c6': 6}\n",
        "\n",
        "    directions = []\n",
        "    distances = []\n",
        "    for k, v in params.items():\n",
        "        directions.append(latent_dirs[param_indexes[k]])\n",
        "        distances.append(v)\n",
        "\n",
        "    w1 = model.sample_latent(1, seed=seed1).detach().cpu().numpy()\n",
        "    w1 = [w1]*model.get_max_latents() # one per layer\n",
        "    im1 = model.sample_np(w1)\n",
        "\n",
        "    w2 = model.sample_latent(1, seed=seed2).detach().cpu().numpy()\n",
        "    w2 = [w2]*model.get_max_latents() # one per layer\n",
        "    im2 = model.sample_np(w2)\n",
        "    combined_im = np.concatenate([im1, im2], axis=1)\n",
        "    input_im = Image.fromarray((combined_im * 255).astype(np.uint8))\n",
        "    \n",
        "\n",
        "    mixed_w = mix_w(w1, w2, content, style)\n",
        "    return input_im, display_sample_pytorch(seed1, truncation, directions, distances, scale, int(start_layer), int(end_layer), w=mixed_w, disp=False)\n",
        "\n",
        "truncation = gr.inputs.Slider(minimum=0, maximum=1, default=0.5, label=\"Truncation\")\n",
        "start_layer = gr.inputs.Number(default=0, label=\"Start Layer\")\n",
        "end_layer = gr.inputs.Number(default=14, label=\"End Layer\")\n",
        "seed1 = gr.inputs.Number(default=0, label=\"Seed 1\")\n",
        "seed2 = gr.inputs.Number(default=0, label=\"Seed 2\")\n",
        "content = gr.inputs.Slider(label=\"Structure\", minimum=0, maximum=1, default=0.5)\n",
        "style = gr.inputs.Slider(label=\"Style\", minimum=0, maximum=1, default=0.5)\n",
        "\n",
        "slider_max_val = 20\n",
        "slider_min_val = -20\n",
        "slider_step = 1\n",
        "\n",
        "c0 = gr.inputs.Slider(label=\"Sleeve & Size\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c1 = gr.inputs.Slider(label=\"Dress - Jacket\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c2 = gr.inputs.Slider(label=\"Female Coat\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c3 = gr.inputs.Slider(label=\"Coat\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c4 = gr.inputs.Slider(label=\"Graphics\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c5 = gr.inputs.Slider(label=\"Dark\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c6 = gr.inputs.Slider(label=\"Less Cleavage\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "\n",
        "\n",
        "scale = 1\n",
        "\n",
        "inputs = [seed1, seed2, content, style, truncation, c0, c1, c2, c3, c4, c5, c6, start_layer, end_layer]\n",
        "\n",
        "gr.Interface(generate_image, inputs, [\"image\", \"image\"], live=True, title=\"ClothingGAN\").launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ClothingGAN-Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
